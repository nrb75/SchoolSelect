{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schools in Greenville, SC, How are they similar? \n",
    "\n",
    "First do data preprocessing in the \"School_data_preprocessing\" notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The \"All_Cohort\" variable is all students in that school, then they are broken down into racial groups.\n",
    "\n",
    "MAM = American Indian/Alaska Native students\n",
    "\n",
    "MAS = Asian/Pacific Islander\n",
    "\n",
    "MHI = Hispanic/Latino\n",
    "\n",
    "MBL = Black\n",
    "\n",
    "MWH = White\n",
    "\n",
    "MTR = Two or more races\n",
    "\n",
    "CWD = disabilities\n",
    "\n",
    "ECD = Economically disadvanted\n",
    "\n",
    "LEP = Limited English Proficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check that all missing values are correctly filled in or removed prior to clustering algorithims which cannot handle NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_list=grad_2015.isna().sum()\n",
    "na_list/len(grad_2015) # percentage\n",
    "#Because many of these race groups are so small the PS identifier was used, and then converted to NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(grad_2015['ALL_RATE_1516']) #most schools have above 80% graduation, but there is some negative skewing down towards lower rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First look at clustering based on graduation rates only, also broken down by race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We do not need the school name, NCESSCH, FIPST, or LEAID variables in clustering. We also remove the statename and leanm\n",
    "cluster_data=grad_2015.drop(['NCESSCH', 'FIPST', 'LEAID', 'SCHNAM', 'DATE_CUR', 'STNAM', 'LEANM'], axis=1)\n",
    "cluster_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start with Principal Component Analysis (PCA) to visuzlize data and see if there are any clusters\n",
    "\n",
    "PCA takes all of the data variables for each datapoint, and trys to create n axis (usually 2-3) that summarizes all of that variability into a meaningful way. Example, if we start with 10 variables, we could condense this down into 2 variables and then plot the data on these new 2 variable axes (like an x-y axis plot).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Use StandardScaler to help you standardize the datasetâ€™s features onto unit scale (mean = 0 and variance = 1) \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardizing the features\n",
    "cluster_data.iloc[:, 2:] = StandardScaler().fit_transform(cluster_data.iloc[:, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "principalComponents = pca.fit_transform(cluster_data)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "            , columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalDf.head()\n",
    "\n",
    "plt.scatter(principalDf['principal component 1'],principalDf['principal component 2'], s=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "#do k-means clustering on 2 components created earlier\n",
    "labels = KMeans(2, random_state=0).fit_predict(principalDf)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalDf['kmeans']=labels\n",
    "plt.scatter(principalDf['principal component 1'],principalDf['principal component 2'], s=50, c=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data['kmeans']=labels\n",
    "grad_2015['kmeans']=labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the cluster classification compares across different graduating trends by race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_2015[['kmeans', 'ALL_RATE_1516', 'MBL_RATE_1516']].groupby(['kmeans'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clustering on just the graduation data did not seem to help, let's see if pulling in other data will improve our model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
